{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oRWvUPFskKZk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "from plotnine import *\n",
        "from lifelines import KaplanMeierFitter\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines.statistics import logrank_test\n",
        "import numpy as np\n",
        "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
        "from sksurv.util import Surv\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.metrics import make_scorer\n",
        "from sksurv.metrics import concordance_index_censored\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from lifelines import CoxPHFitter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from lifelines import WeibullAFTFitter\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.metrics import brier_score\n",
        "from scipy.integrate import trapezoid\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, ConfusionMatrixDisplay, accuracy_score,\n",
        "    precision_score, recall_score, roc_auc_score\n",
        ")\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Data into df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5AKrJT3lfwz"
      },
      "outputs": [],
      "source": [
        "file_path = \"\"\n",
        "# Read the Parquet file\n",
        "table = pq.read_table(file_path)\n",
        "\n",
        "# Convert to a pandas DataFrame if needed\n",
        "df = table.to_pandas()\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contract Renewal Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure 'date' is in datetime format\n",
        "df[\"calendar_date\"] = pd.to_datetime(df[\"calendar_date\"])\n",
        "df[\"target_date\"] = pd.to_datetime(df[\"target_date\"])\n",
        "df[\"contract_end_date\"] = pd.to_datetime(df[\"contract_end_date\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## remain_contract_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remain_contract_month: months left in a contract and ensure it doesn't go below 0\n",
        "df['remain_contract_month'] = ((df['contract_end_date'] - df['calendar_date']).dt.days / 30).round()\n",
        "df['remain_contract_month'] = df['remain_contract_month'].clip(lower=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## df_changes\n",
        "\n",
        "extracting date information and grouping by contract_end_date per customer. \n",
        "\n",
        "df_changes contains repeats of customer id's but only one contract per row!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the column to datetime format\n",
        "df['contract_end_date'] = pd.to_datetime(df['contract_end_date'])\n",
        "\n",
        "# Extract year, month, and day as separate columns\n",
        "df['year'] = df['contract_end_date'].dt.year\n",
        "df['month'] = df['contract_end_date'].dt.month\n",
        "df['day'] = df['contract_end_date'].dt.day\n",
        "\n",
        "# Identify rows where any of year, month, or day changes compared to the previous row\n",
        "df_changes = df[(df['year'].ne(df['year'].shift())) |\n",
        "                (df['month'].ne(df['month'].shift())) |\n",
        "                (df['day'].ne(df['day'].shift())) |\n",
        "                (df['time_step'] == 1)] \n",
        "\n",
        "df_changes = df_changes[df_changes['remain_contract_month'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display the resulting DataFrame with changes\n",
        "df_changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_changes[(df_changes['time_step']==1)&(df_changes['remain_contract_month']==97)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_changes[df_changes['time_step']==1]['remain_contract_month'].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_changes[(df_changes['cat1']=='A') & (df_changes['cat2']=='A') & (df_changes['cat3']=='B')& (df_changes['time_step']==1)]['remain_contract_month'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### calculating total contract count for each customer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_contract_counts = df_changes.groupby('id').size().reset_index(name='total_contract_count')\n",
        "total_contract_counts.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### contract length calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the last contract length for each customer\n",
        "last_contracts = df_changes.groupby('id').last().reset_index()\n",
        "\n",
        "# Compute contract length statistics, including last contract length\n",
        "contract_lengths = df_changes.groupby('id')['remain_contract_month'].agg(\n",
        "    avg_contract_length='mean',\n",
        "    longest_contract='max',\n",
        "    shortest_contract='min',\n",
        "    std_contract_length='std'\n",
        ").reset_index()\n",
        "\n",
        "# Replace NaN in standard deviation with 0\n",
        "contract_lengths['std_contract_length'] = contract_lengths['std_contract_length'].fillna(0)\n",
        "\n",
        "# Merge the last contract length into contract_lengths\n",
        "contract_lengths = contract_lengths.merge(\n",
        "    last_contracts[['id', 'remain_contract_month']], \n",
        "    on='id', \n",
        "    how='left'\n",
        ").rename(columns={'remain_contract_month': 'last_contract_length'})\n",
        "\n",
        "# last_contract_length / avg_contract_length\n",
        "contract_lengths['last_avg_contract_ratio'] = contract_lengths['last_contract_length'] / contract_lengths['avg_contract_length']\n",
        "\n",
        "# last_contract_length / longest_contract\n",
        "# contract_lengths['last_peak_contract_ratio'] = contract_lengths['last_contract_length'] / contract_lengths['longest_contract']\n",
        "\n",
        "# Display the new DataFrame\n",
        "contract_lengths.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the ratio is close to 1:\n",
        "- The customer's last contract length is consistent with their historical contract lengths, suggesting a stable renewal pattern.\n",
        "- This could indicate that the customer is not changing their behavior significantly before churning (or they may not churn at all).\n",
        "- **if its 1 that means that ALL their contracts are the same length (probable that they only had 1 contract)**\n",
        "\n",
        "If the ratio is lower than 1:\n",
        "- The last contract is shorter than their average contract length.\n",
        "- This might indicate that the customer is hesitating to commit, testing shorter-term contracts before churning.\n",
        "- **they may be shortening their contracts to leave BUT need to establish what ratio is significantly low enough**\n",
        "\n",
        "If the ratio is greater than 1:\n",
        "- The last contract is longer than their historical average.\n",
        "- This could mean the customer has decided to stay longer than usual, perhaps due to a better offer or a change in needs.\n",
        "- **they may be interested in strengthening their commitments with F5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Base data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "#churned customer at the last month before target date\n",
        "churn_last = df[(df['target_label'] == 1) & (df['calendar_date'] == df['target_date']- pd.Timedelta(days=1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn = df[(df['target_label'] == 1) & (df['time_step'] == 1)]\n",
        "churn = churn[churn['contract_end_date']>churn['calendar_date']]\n",
        "\n",
        "#churned customer at the first time step of calendar date\n",
        "churn = churn[['id','calendar_date','target_label','target_date']]\n",
        "#combined churned customer's the first time step of calendar date with the data at the last month before target date\n",
        "churn_info = churn_last[['id','time_step','contract_end_date','x1','x2','x1_cumulative','x2_cumulative','cat1','cat2','cat3']]\n",
        "churn = pd.merge(churn, churn_info, on='id', how='inner')\n",
        "churn = churn.rename(columns={'time_step':'life'})\n",
        "churn = churn[(churn['x1'] != 0) & (churn['x2'] != 0)]\n",
        "churn = churn[churn['contract_end_date']<churn['target_date']]\n",
        "churn = churn.rename(columns={'calendar_date': 'join_date'})\n",
        "churn = churn.rename(columns={'x1': 'last_x1'})\n",
        "churn = churn.rename(columns={'x2': 'last_x2'})\n",
        "churn['x1/x2'] = churn['x1_cumulative'] / churn['x2_cumulative']\n",
        "churn['x1_renew_time'] = churn['x1_cumulative'] / churn['last_x1']\n",
        "churn['x2_renew_time'] = churn['x2_cumulative'] / churn['last_x2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "active_join = df[(df['target_label']==0) & (df['time_step']==1)]\n",
        "active_join = active_join[['id','calendar_date']]\n",
        "active_join = active_join.rename(columns={'calendar_date':'join_date'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "active = df[(df['target_label']==0) & (df['calendar_date']=='2024-09-30') & (df['x1'] != 0) & (df['x2'] != 0)]\n",
        "active = active[(active['customer_status']!='inactive')]\n",
        "active['life'] = active['time_step']\n",
        "active = active.drop(columns=['calendar_date','time_step','customer_status'])\n",
        "active = active.rename(columns={'x1': 'last_x1'})\n",
        "active = active.rename(columns={'x2': 'last_x2'})\n",
        "active['x1/x2'] = active['x1_cumulative'] / active['x2_cumulative']\n",
        "active['x1_renew_time'] = active['x1_cumulative'] / active['last_x1']\n",
        "active['x2_renew_time'] = active['x2_cumulative'] / active['last_x2']\n",
        "active = pd.merge(active_join, active, on='id', how='inner')\n",
        "active = active[active['contract_end_date']<'2040-01-31']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating 'clean' dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean = pd.concat([active,churn])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating agg_stats for x1 & x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Filter the DataFrame for rows where calendar_date is prior to target_date or target_label == 0\n",
        "filtered_df = df[(df['calendar_date'] < df['target_date']) | (df['target_label'] == 0)]\n",
        "\n",
        "# Define the columns for which you want to calculate statistics\n",
        "columns_to_aggregate = ['x1', 'x2', 'x1_cumulative', 'x2_cumulative']\n",
        "\n",
        "# Group by 'id' and calculate the mean, median, min, max, and std for the selected columns\n",
        "agg_stats = filtered_df.groupby('id')[columns_to_aggregate].agg(['mean', 'median', 'min', 'max', 'std'])\n",
        "\n",
        "# Flatten the multi-level column index\n",
        "agg_stats.columns = ['_'.join(col) for col in agg_stats.columns]\n",
        "\n",
        "# Reset the index to convert the result back into a DataFrame\n",
        "agg_stats = agg_stats.reset_index()\n",
        "\n",
        "# Display the aggregated statistics\n",
        "print(agg_stats)\n",
        "\n",
        "agg_stats.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging datasets INTO clean\n",
        "\n",
        "agg_stats, contract_lengths, total_contract_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean = clean.merge(agg_stats, on='id', how='left')\n",
        "clean = clean.merge(contract_lengths, on='id', how='left')\n",
        "clean = clean.merge(total_contract_counts, on='id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean['x1_std'] = clean['x1_std'].fillna(0)\n",
        "clean['x2_std'] = clean['x2_std'].fillna(0)\n",
        "clean['x1_cumulative_std'] = clean['x1_cumulative_std'].fillna(0)\n",
        "clean['x2_cumulative_std'] = clean['x2_cumulative_std'].fillna(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create dataset at certain time point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_df(df, time_point, future_point, id_list):\n",
        "    \"\"\"\n",
        "    Process the dataframe based on specified conditions and return a new dataframe.\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): The input dataframe.\n",
        "        time_point (int/float): The reference time point.\n",
        "        future_point (int/float): The future time point to evaluate customer status.\n",
        "        id_list (list): List of IDs to filter.\n",
        "    \n",
        "    Returns:\n",
        "        pd.DataFrame: Processed dataframe with aggregated statistics.\n",
        "    \"\"\"\n",
        "    # Filter dataframe based on id_list\n",
        "    if isinstance(id_list, pd.DataFrame):\n",
        "        id_list = id_list['id'].tolist()  # Convert column to a list\n",
        "    filtered_df = df[df['id'].isin(id_list)]\n",
        "\n",
        "    # Exclude IDs where customer_status is 'inactive' at time_step == time_point\n",
        "    active_at_time_point = filtered_df[(filtered_df['time_step'] == time_point) & (filtered_df['customer_status'] != 'inactive')]['id'].unique()\n",
        "    filtered_df = filtered_df[filtered_df['id'].isin(active_at_time_point)]\n",
        "\n",
        "    # Create target_label based on future customer status\n",
        "    future_status = filtered_df[filtered_df['time_step'] == future_point]\n",
        "    valid_future_ids = future_status['id'].unique()\n",
        "    \n",
        "    # Remove IDs that do not have future_point data\n",
        "    filtered_df = filtered_df[filtered_df['id'].isin(valid_future_ids)]\n",
        "    \n",
        "    target_map = dict(zip(future_status['id'], (future_status['customer_status'] == 'inactive').astype(int)))\n",
        "    filtered_df['target_label'] = filtered_df['id'].map(target_map).fillna(0).astype(int)\n",
        "    \n",
        "    # Filter rows where time_step <= time_point\n",
        "    filtered_df = filtered_df[filtered_df['time_step'] <= time_point]\n",
        "    \n",
        "    # Define columns for aggregation\n",
        "    columns_to_aggregate = ['x1', 'x2', 'x1_cumulative', 'x2_cumulative']\n",
        "    \n",
        "    # Group by 'id' and compute statistical aggregations\n",
        "    agg_stats = filtered_df.groupby('id')[columns_to_aggregate].agg(['mean', 'median', 'min', 'max', 'std'])\n",
        "    \n",
        "    # Flatten multi-level columns\n",
        "    agg_stats.columns = ['_'.join(col) for col in agg_stats.columns]\n",
        "    \n",
        "    # Reset index\n",
        "    agg_stats = agg_stats.reset_index()\n",
        "\n",
        "    filtered_df['remain_contract_month'] = ((filtered_df['contract_end_date'] - filtered_df['calendar_date']).dt.days / 30).round()\n",
        "    filtered_df['remain_contract_month'] = filtered_df['remain_contract_month'].clip(lower=0)\n",
        "\n",
        "    # Identify rows where any of year, month, or day changes compared to the previous row\n",
        "    df_changes = filtered_df[(filtered_df['year'].ne(filtered_df['year'].shift())) |\n",
        "                (filtered_df['month'].ne(filtered_df['month'].shift())) |\n",
        "                (filtered_df['day'].ne(filtered_df['day'].shift())) |\n",
        "                (filtered_df['time_step'] == 1)] \n",
        "    df_changes = df_changes[df_changes['remain_contract_month'] > 0]\n",
        "\n",
        "    # Extract the last contract length for each customer\n",
        "    last_contracts = df_changes.groupby('id').last().reset_index()\n",
        "\n",
        "    # Compute contract length statistics, replacing NaN std with 0\n",
        "    contract_lengths = df_changes.groupby('id')['remain_contract_month'].agg(\n",
        "    avg_contract_length='mean',\n",
        "    longest_contract='max',\n",
        "    shortest_contract='min',\n",
        "    std_contract_length='std'\n",
        "    ).reset_index()\n",
        "\n",
        "    # Replace NaN in standard deviation with 0\n",
        "    contract_lengths['std_contract_length'] = contract_lengths['std_contract_length'].fillna(0)\n",
        "\n",
        "    # Merge the last contract length into contract_lengths\n",
        "    contract_lengths = contract_lengths.merge(\n",
        "        last_contracts[['id', 'remain_contract_month']], \n",
        "        on='id', \n",
        "        how='left'\n",
        "    ).rename(columns={'remain_contract_month': 'last_contract_length'})\n",
        "\n",
        "    # last_contract_length / avg_contract_length\n",
        "    contract_lengths['last_avg_contract_ratio'] = contract_lengths['last_contract_length'] / contract_lengths['avg_contract_length']\n",
        "\n",
        "\n",
        "    total_contract_counts = df_changes.groupby('id').size().reset_index(name='total_contract_count')\n",
        "\n",
        "\n",
        "    # Take only the rows where `time_step == time_point` for feature engineering\n",
        "    filtered_df = filtered_df[filtered_df['time_step'] == time_point]\n",
        "    \n",
        "    # Rename columns\n",
        "    filtered_df = filtered_df.rename(columns={'x1': 'last_x1', 'x2': 'last_x2'})\n",
        "\n",
        "    # Rename columns\n",
        "    filtered_df = filtered_df.rename(columns={'x1': 'last_x1', 'x2': 'last_x2'})\n",
        "    \n",
        "    # Compute derived features\n",
        "    filtered_df['x1/x2'] = filtered_df['x1_cumulative'] / filtered_df['x2_cumulative']\n",
        "    filtered_df['x1_renew_time'] = filtered_df['x1_cumulative'] / filtered_df['last_x1']\n",
        "    filtered_df['x2_renew_time'] = filtered_df['x2_cumulative'] / filtered_df['last_x2']\n",
        "\n",
        "    # Merge with agg_stats\n",
        "    filtered_df = filtered_df.merge(agg_stats, on='id', how='left')\n",
        "    filtered_df = filtered_df.merge(contract_lengths, on='id', how='left')\n",
        "    filtered_df = filtered_df.merge(total_contract_counts, on='id', how='left')\n",
        "\n",
        "\n",
        "    return filtered_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create datasets for clustering (only cat1 and cat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean['Category_Combo2'] = clean['cat1'] + '-' + clean['cat2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_id = clean[~clean['Category_Combo2'].isin(['N/A-A', 'D-N/A', 'C-N/A'])]['id'].to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_12 = create_df(df, 12, 12, cluster_id)\n",
        "cluster_12 = cluster_12.merge(clean[['id', 'Category_Combo2']], on='id', how='left')\n",
        "\n",
        "cluster_24 = create_df(df, 24, 24, cluster_id)\n",
        "cluster_24 = cluster_24.merge(clean[['id', 'Category_Combo2']], on='id', how='left')\n",
        "\n",
        "cluster_36 = create_df(df, 36, 36, cluster_id)\n",
        "cluster_36 = cluster_36.merge(clean[['id', 'Category_Combo2']], on='id', how='left') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_18 = create_df(df, 18, 18, cluster_id)\n",
        "cluster_18 = cluster_18.merge(clean[['id', 'Category_Combo2']], on='id', how='left') \n",
        "\n",
        "cluster_30 = create_df(df, 30, 30, cluster_id)\n",
        "cluster_30 = cluster_30.merge(clean[['id', 'Category_Combo2']], on='id', how='left') \n",
        "\n",
        "cluster_48 = create_df(df, 48, 48, cluster_id)\n",
        "cluster_48 = cluster_48.merge(clean[['id', 'Category_Combo2']], on='id', how='left') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_12_median = cluster_12.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2', 'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].median().reset_index()\n",
        "\n",
        "cluster_24_median = cluster_24.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2', 'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].median().reset_index()\n",
        "\n",
        "cluster_36_median = cluster_36.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2', 'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].median().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_18_median = cluster_18.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2', 'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].median().reset_index()\n",
        "\n",
        "cluster_30_median = cluster_30.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2', 'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].median().reset_index()\n",
        "\n",
        "cluster_48_median = cluster_48.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2', 'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].median().reset_index()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mean of the median\n",
        "cluster_median_all = pd.concat([cluster_12_median, cluster_24_median, cluster_36_median,cluster_18_median, cluster_30_median, cluster_48_median], ignore_index=True)\n",
        "cluster_average_all = cluster_median_all.groupby('Category_Combo2')[['last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative','x1/x2',\n",
        "        'x1_renew_time', 'x2_renew_time', 'x1_mean', 'x1_median',\n",
        "       'x1_min', 'x1_max', 'x1_std', 'x2_mean', 'x2_median', 'x2_min',\n",
        "       'x2_max', 'x2_std', 'x1_cumulative_mean', 'x1_cumulative_median',\n",
        "       'x1_cumulative_min', 'x1_cumulative_max', 'x1_cumulative_std',\n",
        "       'x2_cumulative_mean', 'x2_cumulative_median', 'x2_cumulative_min',\n",
        "       'x2_cumulative_max', 'x2_cumulative_std', 'avg_contract_length',\n",
        "       'longest_contract', 'shortest_contract', 'std_contract_length',\n",
        "       'last_contract_length', 'last_avg_contract_ratio',\n",
        "       'total_contract_count']].mean().reset_index()\n",
        "\n",
        "cluster_average_all.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PCA (only cat1 and cat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_feature = cluster_average_all[[\n",
        "    'last_x1', 'x1/x2', 'x2_cumulative_min', \n",
        "    'avg_contract_length', 'longest_contract', 'total_contract_count']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic data\n",
        "np.random.seed(42)\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(cluster_feature)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=4)  # Reduce to 4 components\n",
        "data_pca = pca.fit_transform(data_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pick K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Range of clusters to try\n",
        "k_values = range(1, 11)\n",
        "wcss = []  # List to store Within-Cluster Sum of Squares\n",
        "\n",
        "# Calculate WCSS for each value of k\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(data_pca)\n",
        "    wcss.append(kmeans.inertia_)  # Inertia is the WCSS\n",
        "\n",
        "# Plot the Elbow Method graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, wcss, marker='o', linestyle='-', color='blue')\n",
        "plt.title('Elbow Method For Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "plt.xticks(k_values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Apply K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=7, random_state=42)\n",
        "clusters = kmeans.fit_predict(data_pca)\n",
        "\n",
        "cluster_colors = {0: 'blue', 1: 'green', 2: 'orange', 3: 'purple', 4: 'red', 5: 'black', 6: 'grey'}\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "for cluster, color in cluster_colors.items():\n",
        "    subset = data_pca[clusters == cluster]\n",
        "    plt.scatter(subset[:, 0], subset[:, 1], color=color, label=f'Cluster {cluster}', alpha=0.6)\n",
        "\n",
        "plt.xlabel('Principal Component 1 (PC1)')\n",
        "plt.ylabel('Principal Component 2 (PC2)')\n",
        "plt.title('Clusters after PCA')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a DataFrame to inspect the principal components resulting from PCA transformation\n",
        "\n",
        "pd.DataFrame(pca.components_, columns=cluster_feature.columns, index=[f'PC{i+1}' for i in range(pca.n_components_)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the cluster centers from the KMeans model after clustering in the PCA-transformed space\n",
        "cluster_centers_pca = kmeans.cluster_centers_\n",
        "pd.DataFrame(pca.inverse_transform(cluster_centers_pca), columns=cluster_feature.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_average_all['cluster'] = clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_average_all['Final_Profile'] = cluster_average_all['cluster'].replace({\n",
        "    0: \"Big Fish\",\n",
        "    1: \"Hidden Gem\",\n",
        "    2: \"Rising Legacy\",\n",
        "    3: \"Fairweather Friend\",\n",
        "    4: \"Small Fish\",\n",
        "    5: \"Legacy\",\n",
        "    6: \"Silent Volcano\"   \n",
        "})\n",
        "\n",
        "profile_breakdown = cluster_average_all[['Category_Combo2', 'Final_Profile']].drop_duplicates().groupby('Final_Profile')['Category_Combo2'].apply(list)\n",
        "for profile, categories in profile_breakdown.items():\n",
        "    print(f\"\\nðŸ“Œ {profile} ({len(categories)} groups):\")\n",
        "    print(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_plot = cluster_average_all[[\n",
        "    'Category_Combo2','cluster','last_x1', 'x1/x2', 'x2_cumulative_min', \n",
        "    'avg_contract_length', 'longest_contract', 'total_contract_count']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_plot.groupby('cluster')[['last_x1', 'x1/x2', 'x2_cumulative_min', \n",
        "    'avg_contract_length', 'longest_contract', 'total_contract_count']].agg('mean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Spectral Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure the data is in array format\n",
        "#X = data_pca.to_numpy()\n",
        "\n",
        "# Spectral Clustering\n",
        "sc = SpectralClustering(n_clusters=7, affinity='nearest_neighbors', assign_labels='kmeans', random_state=42)\n",
        "clusters2 = sc.fit_predict(data_scaled)\n",
        "\n",
        "# Plot using meaningful features (or first two PCA components)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(data_scaled[:, 0], data_scaled[:, 1], c=clusters2, cmap='viridis', s=50, alpha=0.7)\n",
        "plt.xlabel('last_x1')   # Update to match actual feature names\n",
        "plt.ylabel('avg_contract_length')\n",
        "plt.title('Spectral Clustering on Original Data')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_average_all['cluster2'] = clusters2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_average_all.groupby('cluster2')[['last_x1', 'x1/x2', 'x2_cumulative_min', \n",
        "    'avg_contract_length', 'longest_contract', 'total_contract_count']].agg('mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "silhouette_kmeans = silhouette_score(data_pca, clusters)\n",
        "silhouette_spectral = silhouette_score(data_scaled, clusters2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"KMeans Silhouette: {silhouette_kmeans:.4f}\")\n",
        "print(f\"Spectral Silhouette: {silhouette_spectral:.4f}\")\n",
        "# KMeans has lower Silhouette score, we decide to use KMeans instead of Spectral "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Kaplan-Meier Estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data\n",
        "T = clean['life']  # Time to event (e.g., duration in days)\n",
        "E = clean['target_label']  # Event indicator (1=event occurred, 0=censored)\n",
        "\n",
        "# Fit Kaplan-Meier estimator\n",
        "kmf = KaplanMeierFitter()\n",
        "kmf.fit(T, event_observed=E)\n",
        "\n",
        "# Plot survival curve\n",
        "kmf.plot_survival_function()\n",
        "plt.title('Kaplan-Meier Survival Curve')\n",
        "plt.xlabel('Time(month)')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cox Proportional Hazards Model\n",
        "Once a Cox model is fitted, you can generate survival curves based on specific predictor values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'last_x1': [20], 'last_x2': [20],  \n",
        "'x1_cumulative': [50], 'x2_cumulative': [50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit Cox Proportional Hazards model\n",
        "cox_df = clean[['life', 'target_label', 'last_x1', 'last_x2', 'x1_cumulative', 'x2_cumulative']]\n",
        "cox = CoxPHFitter()\n",
        "cox.fit(cox_df, duration_col='life', event_col='target_label')\n",
        "\n",
        "# Predict survival function for a specific individual\n",
        "individual = pd.DataFrame({\n",
        "    'last_x1': [20],\n",
        "    'last_x2': [20],\n",
        "    'x1_cumulative': [50],\n",
        "    'x2_cumulative': [50]\n",
        "})\n",
        "survival_curve = cox.predict_survival_function(individual)\n",
        "\n",
        "# Plot survival curve\n",
        "survival_curve.plot()\n",
        "plt.title('Survival Curve for Individual')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "'last_x1': [2], 'last_x2': [2],  \n",
        "'x1_cumulative': [5], 'x2_cumulative': [5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "individual = pd.DataFrame({\n",
        "    'last_x1': [2],\n",
        "    'last_x2': [2],\n",
        "    'x1_cumulative': [5],\n",
        "    'x2_cumulative': [5]\n",
        "})\n",
        "survival_curve = cox.predict_survival_function(individual)\n",
        "\n",
        "# Plot survival curve\n",
        "survival_curve.plot()\n",
        "plt.title('Survival Curve for Individual')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparing Groups\n",
        "To compare survival curves for groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for group in clean['cat1'].unique():\n",
        "    group_data = clean[clean['cat1'] == group]\n",
        "    kmf.fit(group_data['life'], event_observed=group_data['target_label'], label=str(group))\n",
        "    kmf.plot_survival_function()\n",
        "\n",
        "plt.title('Survival Curves by Group(cat1)')\n",
        "plt.xlabel('Time(month)')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.legend(title='Group')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for group in clean['cat2'].unique():\n",
        "    group_data = clean[clean['cat2'] == group]\n",
        "    kmf.fit(group_data['life'], event_observed=group_data['target_label'], label=str(group))\n",
        "    kmf.plot_survival_function()\n",
        "\n",
        "plt.title('Survival Curves by Group(cat2)')\n",
        "plt.xlabel('Time(month)')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.legend(title='Group')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for group in clean['cat3'].unique():\n",
        "    group_data = clean[clean['cat3'] == group]\n",
        "    kmf.fit(group_data['life'], event_observed=group_data['target_label'], label=str(group))\n",
        "    kmf.plot_survival_function()\n",
        "\n",
        "plt.title('Survival Curves by Group(cat3)')\n",
        "plt.xlabel('Time(month)')\n",
        "plt.ylabel('Survival Probability')\n",
        "plt.legend(title='Group')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Statistical Comparison of three categories survival curves using Log-Rank Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the unique groups in cat1\n",
        "groups_cat1 = clean['cat1'].unique()\n",
        "\n",
        "# Pairwise log-rank tests for all group combinations in cat1\n",
        "for i in range(len(groups_cat1)):\n",
        "    for j in range(i + 1, len(groups_cat1)):\n",
        "        group1 = clean[clean['cat1'] == groups_cat1[i]]\n",
        "        group2 = clean[clean['cat1'] == groups_cat1[j]]\n",
        "        \n",
        "        # Perform log-rank test\n",
        "        result = logrank_test(\n",
        "            group1['life'], group2['life'],\n",
        "            event_observed_A=group1['target_label'],\n",
        "            event_observed_B=group2['target_label']\n",
        "        )\n",
        "        \n",
        "        print(f\"Log-rank test between {groups_cat1[i]} and {groups_cat1[j]}:\")\n",
        "        print(f\"P-value: {result.p_value}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Significant Comparisons (p < 0.05):\n",
        "- D vs A (p = 2.6e-49): Strong evidence of a difference.\n",
        "- D vs B (p = 0.0349): Moderate evidence of a difference.\n",
        "- D vs C (p = 0.0078): Strong evidence of a difference.\n",
        "- A vs B (p = 1.6e-61): Extremely strong evidence of a difference.\n",
        "- A vs C (p = 1.85e-07): Strong evidence of a difference.\n",
        "- B vs C (p = 0.00023): Strong evidence of a difference.\n",
        "\n",
        "Non-Significant Comparisons (p â‰¥ 0.05):\n",
        "- D vs N/A (p = 0.5006): No evidence of a difference.\n",
        "- A vs N/A (p = 0.7213): No evidence of a difference.\n",
        "- B vs N/A (p = 0.4765): No evidence of a difference.\n",
        "- C vs N/A (p = 0.5690): No evidence of a difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "groups_cat2 = clean['cat2'].unique()\n",
        "\n",
        "for i in range(len(groups_cat2)):\n",
        "    for j in range(i + 1, len(groups_cat2)):\n",
        "        group1 = clean[clean['cat2'] == groups_cat2[i]]\n",
        "        group2 = clean[clean['cat2'] == groups_cat2[j]]\n",
        "        \n",
        "        result = logrank_test(\n",
        "            group1['life'], group2['life'],\n",
        "            event_observed_A=group1['target_label'],\n",
        "            event_observed_B=group2['target_label']\n",
        "        )\n",
        "        \n",
        "        print(f\"Log-rank test between {groups_cat2[i]} and {groups_cat2[j]}:\")\n",
        "        print(f\"P-value: {result.p_value}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Significant Comparisons (p < 0.05):\n",
        "- B vs D (p = 0.0): Indicates a very strong difference in survival patterns.\n",
        "- B vs C (p = 1.88e-51): Extremely strong evidence of a difference.\n",
        "- B vs N/A (p = 0.0193): Moderate evidence of a difference.\n",
        "- B vs A (p = 2.2e-05): Strong evidence of a difference.\n",
        "- D vs C (p = 1.17e-139): Extremely strong evidence of a difference.\n",
        "- D vs N/A (p = 6.3e-14): Extremely strong evidence of a difference.\n",
        "- D vs A (p = 1.28e-240): Extremely strong evidence of a difference.\n",
        "- C vs A (p = 1.25e-18): Strong evidence of a difference.\n",
        "\n",
        "Non-Significant Comparisons (p â‰¥ 0.05):\n",
        "- C vs N/A (p = 0.296): No evidence of a difference.\n",
        "- N/A vs A (p = 0.414): No evidence of a difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "groups_cat3 = clean['cat3'].unique()\n",
        "\n",
        "for i in range(len(groups_cat3)):\n",
        "    for j in range(i + 1, len(groups_cat3)):\n",
        "        group1 = clean[clean['cat3'] == groups_cat3[i]]\n",
        "        group2 = clean[clean['cat3'] == groups_cat3[j]]\n",
        "        \n",
        "        result = logrank_test(\n",
        "            group1['life'], group2['life'],\n",
        "            event_observed_A=group1['target_label'],\n",
        "            event_observed_B=group2['target_label']\n",
        "        )\n",
        "        \n",
        "        # print(f\"Log-rank test between {groups_cat3[i]} and {groups_cat3[j]}:\")\n",
        "        # print(f\"P-value: {result.p_value}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature Engineering\n",
        "\n",
        "uses cox proportional hazards model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing inconsistent id's\n",
        "\n",
        "hardcoded removing id's where contract_end_date was incorrectly inputted and later \"revised\" but became a new data entry in 2020. paige will create a solution later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the predictor variables\n",
        "cleaning_X = clean.drop(columns=['join_date', 'contract_end_date', 'target_label', 'target_date', 'life', \n",
        "                        'cat1', 'cat2', 'cat3', 'x2_cumulative', 'x1_cumulative', 'remain_contract_month', 'year', 'month', 'day','Category_Combo2'])\n",
        "\n",
        "cleaning_X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "null_ids = cleaning_X[cleaning_X['last_avg_contract_ratio'].isna()]['id']\n",
        "null_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean = clean[~clean['id'].isin(null_ids)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Choosing important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare survival target\n",
        "y = Surv.from_dataframe('target_label', 'life', clean)\n",
        "\n",
        "# Prepare the predictor variables\n",
        "X = clean.drop(columns=['id', 'join_date', 'contract_end_date', 'target_label', 'target_date', 'life', \n",
        "                        'cat1', 'cat2', 'cat3', 'x2_cumulative', 'x1_cumulative', 'remain_contract_month', 'year', 'month', 'day','Category_Combo2'])\n",
        "\n",
        "\n",
        "# Train-test split (80% train, 20% test) - stratify using the event column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=clean['target_label'])\n",
        "\n",
        "# Train the Cox Proportional Hazards Model\n",
        "cox_model = CoxPHSurvivalAnalysis(tol=1e-6, alpha=0.1)  # Using penalization to prevent overfitting\n",
        "cox_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set using concordance index\n",
        "c_index_test = concordance_index_censored(y_test['target_label'], y_test['life'], cox_model.predict(X_test))[0]\n",
        "print(f\"Test C-index: {c_index_test:.4f}\")\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_scores = []\n",
        "\n",
        "for train_idx, val_idx in cv.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train[train_idx], y_train[val_idx]  # Directly indexing `y_train`\n",
        "    \n",
        "    # Fit model on training data\n",
        "    cox_model.fit(X_tr, y_tr)\n",
        "    \n",
        "    # Predict on validation data and compute C-index\n",
        "    c_index = concordance_index_censored(y_val['target_label'], y_val['life'], cox_model.predict(X_val))[0]\n",
        "    cv_scores.append(c_index)\n",
        "\n",
        "print(f\"Cross-validation C-index scores: {cv_scores}\")\n",
        "print(f\"Mean C-index (cross-validation): {np.mean(cv_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Feature Importance (Coefficients)\n",
        "importance_df = pd.DataFrame({\n",
        "    'covariate': X.columns,\n",
        "    'Importance': cox_model.coef_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importance\n",
        "print(importance_df)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['covariate'], importance_df['Importance'])\n",
        "plt.xlabel('Feature Importance (Coefficients)')\n",
        "plt.title('Feature Importance from Cox Proportional Hazards Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MultiCollinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"covariate\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### P-values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert data to lifelines format\n",
        "lifelines_df = clean.drop(columns=['id', 'join_date', 'contract_end_date', 'target_date', 'cat1', 'cat2', 'cat3','remain_contract_month', 'year', 'month', 'day'])\n",
        "lifelines_df['event'] = lifelines_df['target_label']\n",
        "lifelines_df['time'] = lifelines_df['life']\n",
        "\n",
        "# Fit Cox model using lifelines\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(lifelines_df, duration_col='time', event_col='event')\n",
        "\n",
        "# Print summary (includes coefficients, standard errors, and p-values)\n",
        "print(cph.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Significant features using P-value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit Cox model using lifelines\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(lifelines_df, duration_col='time', event_col='event')\n",
        "\n",
        "# Print summary (includes coefficients, standard errors, and p-values)\n",
        "summary_df = cph.summary\n",
        "\n",
        "# Filter for features with p-value < 0.05 (significant)\n",
        "feature_significance = summary_df[['p']]  # Keep all needed columns\n",
        "feature_significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final set of important features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_features = feature_significance\n",
        "important_features = important_features.merge(vif_data, on='covariate')\n",
        "important_features = important_features.merge(importance_df, on='covariate')\n",
        "important_features['Importance'] = abs(important_features['Importance'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_features = important_features[important_features['p'] < 0.05]\n",
        "important_features.sort_values(by='VIF')\n",
        "important_features = important_features[important_features['Importance'] > 0.05]\n",
        "important_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model using CHOSEN Important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the survival target (ensure correct column names)\n",
        "y = Surv.from_dataframe('target_label', 'life', clean)\n",
        "\n",
        "# Prepare the predictor variables\n",
        "X = clean[['last_x1', 'x1/x2', 'x2_cumulative_min', 'last_avg_contract_ratio', 'longest_contract', 'total_contract_count']]\n",
        "\n",
        "# Train-test split (80% train, 20% test) - stratify using the event column\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=clean['target_label'])\n",
        "\n",
        "# Train the Cox Proportional Hazards Model\n",
        "cox_model = CoxPHSurvivalAnalysis(tol=1e-6, alpha=0.1)  # Using penalization to prevent overfitting\n",
        "cox_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set using concordance index\n",
        "c_index_test = concordance_index_censored(y_test['target_label'], y_test['life'], cox_model.predict(X_test))[0]\n",
        "print(f\"Test C-index: {c_index_test:.4f}\")\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "cv_scores = []\n",
        "\n",
        "for train_idx, val_idx in cv.split(X_train):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "    y_tr, y_val = y_train[train_idx], y_train[val_idx]  # Directly indexing `y_train`\n",
        "    \n",
        "    # Fit model on training data\n",
        "    cox_model.fit(X_tr, y_tr)\n",
        "    \n",
        "    # Predict on validation data and compute C-index\n",
        "    c_index = concordance_index_censored(y_val['target_label'], y_val['life'], cox_model.predict(X_val))[0]\n",
        "    cv_scores.append(c_index)\n",
        "\n",
        "print(f\"Cross-validation C-index scores: {cv_scores}\")\n",
        "print(f\"Mean C-index (cross-validation): {np.mean(cv_scores):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract Feature Importance (Coefficients)\n",
        "importance_df = pd.DataFrame({\n",
        "    'covariate': X.columns,\n",
        "    'Importance': cox_model.coef_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display feature importance\n",
        "print(importance_df)\n",
        "\n",
        "# Plot feature importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(importance_df['covariate'], importance_df['Importance'])\n",
        "plt.xlabel('Feature Importance (Coefficients)')\n",
        "plt.title('Feature Importance from Cox Proportional Hazards Model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert data to lifelines format\n",
        "lifelines_df = clean[['target_label', 'life', 'last_x1', 'x1/x2', 'x2_cumulative_min', 'last_avg_contract_ratio', 'total_contract_count','longest_contract']]\n",
        "lifelines_df['event'] = lifelines_df['target_label']\n",
        "lifelines_df['time'] = lifelines_df['life']\n",
        "\n",
        "# Fit Cox model using lifelines\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(lifelines_df, duration_col='time', event_col='event')\n",
        "\n",
        "# Print summary (includes coefficients, standard errors, and p-values)\n",
        "print(cph.summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit Cox model using lifelines\n",
        "cph = CoxPHFitter()\n",
        "cph.fit(lifelines_df, duration_col='time', event_col='event')\n",
        "\n",
        "# Print summary (includes coefficients, standard errors, and p-values)\n",
        "summary_df = cph.summary\n",
        "\n",
        "# Filter for features with p-value < 0.05 (significant)\n",
        "feature_significance = summary_df[['p']]  # Keep all needed columns\n",
        "feature_significance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"covariate\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Chosen Important Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_features_chosen = feature_significance\n",
        "important_features_chosen = important_features_chosen.merge(vif_data, on='covariate')\n",
        "important_features_chosen = important_features_chosen.merge(importance_df, on='covariate')\n",
        "important_features_chosen['Importance_Interpret'] = important_features_chosen['Importance']\n",
        "important_features_chosen['Importance'] = abs(important_features_chosen['Importance'])\n",
        "\n",
        "important_features_chosen.sort_values('Importance_Interpret', ascending=False)\n",
        "important_features_chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_features_chosen['covariate'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# COX PROPORTIONAL MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "important_features = [\n",
        "    'last_x1', 'x1/x2', 'x2_cumulative_min', \n",
        "    'avg_contract_length', 'longest_contract', 'total_contract_count']\n",
        "\n",
        "# Prepare the survival target\n",
        "y = Surv.from_dataframe(\"target_label\", \"life\", clean)\n",
        "\n",
        "# Prepare the predictor variables using only the important features\n",
        "X = clean[important_features]\n",
        "\n",
        "# Train-test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=clean[\"target_label\"]\n",
        ")\n",
        "\n",
        "# Train the Cox Proportional Hazards Model\n",
        "cox_model = CoxPHSurvivalAnalysis(tol=1e-6, alpha=0.1)  # L2 Regularization to prevent overfitting\n",
        "cox_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract 'life' (event/censoring time) from y_test\n",
        "life_values = y_test[\"life\"]  \n",
        "\n",
        "# Get the maximum observed time from training data\n",
        "max_time = y_train[\"life\"].max()\n",
        "\n",
        "# Create a dictionary to store predictions\n",
        "future_predictions = {\"life + 12\": [], \"life + 18\": [], \"life + 24\": [], \"life + 36\": []}\n",
        "\n",
        "# Get survival functions for each customer\n",
        "survival_functions = cox_model.predict_survival_function(X_test)\n",
        "\n",
        "# Define future time points in absolute months (not adding to customer age)\n",
        "time_offsets = [12, 18, 24, 36]  # Months\n",
        "\n",
        "# Iterate over each individual's survival function and life time\n",
        "for fn, life in zip(survival_functions, y_test[\"life\"]):\n",
        "    \n",
        "    # Predict survival probability at life + t (but cap at max_time)\n",
        "    for t in time_offsets:\n",
        "        adjusted_time = min(life + t, max_time)  # Ensure we don't exceed max_time\n",
        "        future_predictions[f\"life + {t}\"].append(fn(adjusted_time))  # Use adjusted time\n",
        "\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "future_pred_df = pd.DataFrame(future_predictions, index=X_test.index)\n",
        "\n",
        "# Retrieve customer IDs from the original dataset\n",
        "customer_ids = clean.loc[X_test.index, \"id\"]\n",
        "\n",
        "# Add Customer IDs to the predictions DataFrame\n",
        "future_pred_df[\"id\"] = customer_ids\n",
        "\n",
        "# Move 'Customer ID' to the first column for better readability\n",
        "future_pred_df = future_pred_df.set_index(\"id\")\n",
        "\n",
        "# Display first few rows\n",
        "print(future_pred_df.head(10))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## integrated brier score for cox proportional model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Convert y_train and y_test into structured arrays for sksurv compatibility\n",
        "survival_train = np.array([(event, time) for event, time in zip(y_train[\"target_label\"], y_train[\"life\"])],\n",
        "                          dtype=[('event', bool), ('time', float)])\n",
        "\n",
        "survival_test = np.array([(event, time) for event, time in zip(y_test[\"target_label\"], y_test[\"life\"])],\n",
        "                         dtype=[('event', bool), ('time', float)])\n",
        "\n",
        "# Define time points at which to evaluate the Brier score\n",
        "times = np.percentile(y_test[\"life\"], np.linspace(10, 90, 20))  # Select meaningful time points\n",
        "\n",
        "# Predict survival functions for test data\n",
        "survival_preds = cox_model.predict_survival_function(X_test)\n",
        "\n",
        "# Convert predictions into an estimate matrix\n",
        "estimate = np.vstack([fn(times) for fn in survival_preds])\n",
        "\n",
        "# Compute Brier scores at different time points\n",
        "brier_scores = brier_score(survival_train, survival_test, estimate, times)\n",
        "\n",
        "# Extract the Brier scores (second element in the tuple)\n",
        "brier_scores = brier_scores[1]\n",
        "\n",
        "# Now compute the Integrated Brier Score\n",
        "integrated_brier_score = trapezoid(brier_scores, times) / (times.max() - times.min())\n",
        "\n",
        "# Convert to scalar\n",
        "integrated_brier_score = float(integrated_brier_score)\n",
        "\n",
        "print(f\"Integrated Brier Score for Cox Model: {integrated_brier_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Convert y_train and y_test into structured arrays for sksurv compatibility\n",
        "survival_train = np.array([(event, time) for event, time in zip(y_train[\"target_label\"], y_train[\"life\"])],\n",
        "                          dtype=[('event', bool), ('time', float)])\n",
        "\n",
        "survival_test = np.array([(event, time) for event, time in zip(y_test[\"target_label\"], y_test[\"life\"])],\n",
        "                         dtype=[('event', bool), ('time', float)])\n",
        "\n",
        "# Define time points at which to evaluate the Brier score\n",
        "times = np.percentile(y_test[\"life\"], np.linspace(20, 90, 10))  # Select meaningful time points\n",
        "\n",
        "# Predict survival functions for test data\n",
        "survival_preds = cox_model.predict_survival_function(X_test)\n",
        "\n",
        "# Convert predictions into an estimate matrix\n",
        "estimate = np.row_stack([fn(times) for fn in survival_preds])\n",
        "\n",
        "# Compute Brier scores at different time points\n",
        "brier_scores = brier_score(survival_train, survival_test, estimate, times)\n",
        "\n",
        "# Compute Integrated Brier Score (mean of all time points)\n",
        "integrated_brier_score = np.mean(brier_scores)\n",
        "\n",
        "# Display the Integrated Brier Score\n",
        "print(f\"Integrated Brier Score for Cox Model: {integrated_brier_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "future_pred_df.sort_values(by=\"life + 36\", ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_future_cox_36_month = future_pred_df[\"life + 36\"].sort_values(ascending=True)\n",
        "sorted_future_cox_36_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_future_cox_12_month = future_pred_df[\"life + 12\"].sort_values(ascending=True)\n",
        "sorted_future_cox_12_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sorted_future_cox_18_month = future_pred_df[\"life + 18\"].sort_values(ascending=True)\n",
        "sorted_future_cox_18_month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WEIBULL - uses weibull distribution for future predictions\n",
        "### this is what we presented in the mid point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define predictor features\n",
        "important_features = [\n",
        " 'last_x1', 'x1/x2', 'x2_cumulative_min',\n",
        " 'longest_contract', 'last_avg_contract_ratio', 'total_contract_count']\n",
        "\n",
        "# Prepare survival target (event indicator and survival time)\n",
        "y = clean[[\"life\", \"target_label\"]]  # Target: survival time & event indicator\n",
        "X = clean[important_features]  # Predictor variables\n",
        "\n",
        "# Train-test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y[\"target_label\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit Weibull AFT Model\n",
        "aft_model = WeibullAFTFitter()\n",
        "aft_model.fit(y_train.join(X_train), duration_col=\"life\", event_col=\"target_label\")\n",
        "\n",
        "# Display model summary\n",
        "aft_model.print_summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Filter active customers (target_label != 1)\n",
        "active_customers = y_test[y_test[\"target_label\"] != 1]\n",
        "\n",
        "#Extract 'age' of each customer\n",
        "customer_ages = active_customers[\"life\"]  # Ensure \"age\" exists in dataset\n",
        "\n",
        "#Keep corresponding features\n",
        "X_active = X_test.loc[active_customers.index]\n",
        "\n",
        "#Define prediction time offsets\n",
        "time_offsets = [12, 24, 36, 48]\n",
        "\n",
        "#Dictionary to store predictions\n",
        "future_aft_predictions = {}\n",
        "\n",
        "#Iterate over time offsets and predict for each customer's future age\n",
        "for t in time_offsets:\n",
        "    future_times = customer_ages + t  # Compute future time for each customer\n",
        "\n",
        "    #Predict survival function at these specific times for each customer\n",
        "    survival_probs = np.array([\n",
        "        aft_model.predict_survival_function(X_active.iloc[i:i+1], times=[future_times.iloc[i]]).values.flatten()[0]\n",
        "        for i in range(len(X_active))\n",
        "    ])\n",
        "\n",
        "    #Store survival probability for each customer at their specific future time\n",
        "    future_aft_predictions[f\"life + {t}\"] = survival_probs\n",
        "\n",
        "#Convert predictions to DataFrame\n",
        "future_aft_df = pd.DataFrame(future_aft_predictions, index=X_active.index)\n",
        "\n",
        "# Add customer IDs for reference\n",
        "customer_ids = clean.loc[X_active.index, \"id\"]\n",
        "future_aft_df[\"id\"] = customer_ids\n",
        "\n",
        "#Move ID column to front\n",
        "future_aft_df = future_aft_df.set_index(\"id\")\n",
        "\n",
        "#Display results\n",
        "future_aft_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "specific_id = \"f7194e770adcb3c8e92c8cb79cfc0615\"\n",
        "row = future_aft_df.loc[specific_id]\n",
        "print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sort DataFrame in ascending order based on 'life + 12' survival probability\n",
        "sorted_aft_df = future_aft_df.sort_values(by=\"life + 12\", ascending=True)\n",
        "\n",
        "# Display first few rows\n",
        "print(sorted_aft_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Brier score at A months predicting B months after(Weibull)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_idx, test_idx = train_test_split(\n",
        "    clean.index, test_size=0.2, random_state=42, stratify=y[\"target_label\"]\n",
        ")\n",
        "\n",
        "# Retrieve the 'id' values for the test set\n",
        "id_test = clean.loc[test_idx, \"id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time point = A months, predicting B months\n",
        "\n",
        "A = 156\n",
        "B = 168\n",
        "\n",
        "score_df = create_df(df, A, B, id_test)\n",
        "\n",
        "# Prepare the survival target\n",
        "score_df_y = Surv.from_dataframe(\"target_label\", \"time_step\", score_df)\n",
        "\n",
        "# Prepare the predictor variables using only the important features\n",
        "score_df_X = score_df[important_features]\n",
        "\n",
        "# Assume df contains 'time' (event/censoring time) and 'target_label' (churn status)\n",
        "time_t = B  # Specify the time at which to compute the Brier Score\n",
        "\n",
        "# Predict survival function for each customer\n",
        "surv_funcs = aft_model.predict_survival_function(score_df_X)\n",
        "\n",
        "# Extract survival probability at time_t\n",
        "surv_probs = surv_funcs.loc[time_t].values\n",
        "\n",
        "# Compute Brier Score\n",
        "y_true = 1 - score_df[\"target_label\"]  # Flip 1 â†’ 0 (churned), 0 â†’ 1 (alive)\n",
        "brier = np.mean((surv_probs - y_true) ** 2)\n",
        "\n",
        "print(f\"Brier Score at t={time_t}: {brier}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Brier, Recall, Precision, Specificity, and Accuracy at A months predicting 12 months after(Weibull)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop over A values from 12 to 168 in steps of 12\n",
        "for A in range(12, 157, 12):  \n",
        "    B = A + 12  # Define B as A + 12\n",
        "\n",
        "    score_df = create_df(df, A, B, id_test)\n",
        "\n",
        "    # Prepare the survival target\n",
        "    score_df_y = Surv.from_dataframe(\"target_label\", \"time_step\", score_df)\n",
        "\n",
        "    # Prepare the predictor variables using only the important features\n",
        "    score_df_X = score_df[important_features]\n",
        "\n",
        "    # Assume df contains 'time' (event/censoring time) and 'target_label' (churn status)\n",
        "    time_t = B  # Specify the time at which to compute the Brier Score\n",
        "\n",
        "    # Predict survival function for each customer\n",
        "    surv_funcs = aft_model.predict_survival_function(score_df_X)\n",
        "\n",
        "    # Extract survival probability at time_t\n",
        "    surv_probs = surv_funcs.loc[time_t].values\n",
        "\n",
        "    # Compute Brier Score\n",
        "    y_true = 1 - score_df[\"target_label\"]  # Flip 1 â†’ 0 (churned), 0 â†’ 1 (alive)\n",
        "    brier = np.mean((surv_probs - y_true) ** 2)\n",
        "\n",
        "        # Convert survival probabilities into binary predictions\n",
        "    y_pred = (surv_probs < 0.6).astype(int)  # Churn if survival probability < 0.5\n",
        "    y_true_original = score_df[\"target_label\"].values  # Use original labels\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true_original, y_pred)\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # Compute classification metrics\n",
        "    accuracy = accuracy_score(y_true_original, y_pred)\n",
        "    precision = precision_score(y_true_original, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true_original, y_pred)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Avoid division by zero\n",
        "\n",
        "    # Store the result\n",
        "    results.append({\n",
        "        \"Model\": \"Weibull\",\n",
        "        \"Time point\": A,\n",
        "        \"Future time\": B,\n",
        "        \"Brier Score\": round(brier, 3),\n",
        "        \"Accuracy\": round(accuracy, 3),\n",
        "        \"Precision\": round(precision, 3),\n",
        "        \"Recall\": round(recall, 3),\n",
        "        \"Specificity\": round(specificity, 3)\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "brier_df_12 = pd.DataFrame(results)\n",
        "print(brier_df_12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "brier_df_12['Brier Score'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Brier, Recall, Precision, Specificity, and Accuracy at A months predicting 24 months after(Weibull)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop over A values from 12 to 168 in steps of 12\n",
        "for A in range(12, 157, 12):  \n",
        "    B = A + 24  # Define B as A + 24\n",
        "\n",
        "    score_df = create_df(df, A, B, id_test)\n",
        "\n",
        "    # Prepare the survival target\n",
        "    score_df_y = Surv.from_dataframe(\"target_label\", \"time_step\", score_df)\n",
        "\n",
        "    # Prepare the predictor variables using only the important features\n",
        "    score_df_X = score_df[important_features]\n",
        "\n",
        "    # Assume df contains 'time' (event/censoring time) and 'target_label' (churn status)\n",
        "    time_t = B  # Specify the time at which to compute the Brier Score\n",
        "\n",
        "    # Predict survival function for each customer\n",
        "    surv_funcs = aft_model.predict_survival_function(score_df_X)\n",
        "\n",
        "    # Extract survival probability at time_t\n",
        "    surv_probs = surv_funcs.loc[time_t].values\n",
        "\n",
        "    # Compute Brier Score\n",
        "    y_true = 1 - score_df[\"target_label\"]  # Flip 1 â†’ 0 (churned), 0 â†’ 1 (alive)\n",
        "    brier = np.mean((surv_probs - y_true) ** 2)\n",
        "\n",
        "        # Convert survival probabilities into binary predictions\n",
        "    y_pred = (surv_probs < 0.6).astype(int)  # Churn if survival probability < 0.5\n",
        "    y_true_original = score_df[\"target_label\"].values  # Use original labels\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true_original, y_pred)\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # Compute classification metrics\n",
        "    accuracy = accuracy_score(y_true_original, y_pred)\n",
        "    precision = precision_score(y_true_original, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true_original, y_pred)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Avoid division by zero\n",
        "\n",
        "    # Store the result\n",
        "    results.append({\n",
        "        \"Model\": \"Weibull\",\n",
        "        \"Time point\": A,\n",
        "        \"Future time\": B,\n",
        "        \"Brier Score\": round(brier, 3),\n",
        "        \"Accuracy\": round(accuracy, 3),\n",
        "        \"Precision\": round(precision, 3),\n",
        "        \"Recall\": round(recall, 3),\n",
        "        \"Specificity\": round(specificity, 3)\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "brier_df_24 = pd.DataFrame(results)\n",
        "print(brier_df_24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "brier_df_24['Brier Score'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Brier, Recall, Precision, Specificity, and Accuracy at A months predicting 36 months after(Weibull)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty list to store results\n",
        "results = []\n",
        "\n",
        "# Loop over A values from 12 to 168 in steps of 12\n",
        "for A in range(12, 157, 12):  \n",
        "    B = A + 36  # Define B as A + 36\n",
        "\n",
        "    score_df = create_df(df, A, B, id_test)\n",
        "\n",
        "    # Prepare the survival target\n",
        "    score_df_y = Surv.from_dataframe(\"target_label\", \"time_step\", score_df)\n",
        "\n",
        "    # Prepare the predictor variables using only the important features\n",
        "    score_df_X = score_df[important_features]\n",
        "\n",
        "    # Assume df contains 'time' (event/censoring time) and 'target_label' (churn status)\n",
        "    time_t = B  # Specify the time at which to compute the Brier Score\n",
        "\n",
        "    # Predict survival function for each customer\n",
        "    surv_funcs = aft_model.predict_survival_function(score_df_X)\n",
        "\n",
        "    # Extract survival probability at time_t\n",
        "    surv_probs = surv_funcs.loc[time_t].values\n",
        "\n",
        "    # Compute Brier Score\n",
        "    y_true = 1 - score_df[\"target_label\"]  # Flip 1 â†’ 0 (churned), 0 â†’ 1 (alive)\n",
        "    brier = np.mean((surv_probs - y_true) ** 2)\n",
        "\n",
        "        # Convert survival probabilities into binary predictions\n",
        "    y_pred = (surv_probs < 0.6).astype(int)  # Churn if survival probability < 0.5\n",
        "    y_true_original = score_df[\"target_label\"].values  # Use original labels\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_true_original, y_pred)\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    # Compute classification metrics\n",
        "    accuracy = accuracy_score(y_true_original, y_pred)\n",
        "    precision = precision_score(y_true_original, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true_original, y_pred)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Avoid division by zero\n",
        "\n",
        "    # Store the result\n",
        "    results.append({\n",
        "        \"Model\": \"Weibull\",\n",
        "        \"Time point\": A,\n",
        "        \"Future time\": B,\n",
        "        \"Brier Score\": round(brier, 3),\n",
        "        \"Accuracy\": round(accuracy, 3),\n",
        "        \"Precision\": round(precision, 3),\n",
        "        \"Recall\": round(recall, 3),\n",
        "        \"Specificity\": round(specificity, 3)\n",
        "    })\n",
        "\n",
        "# Convert results to DataFrame\n",
        "brier_df_36 = pd.DataFrame(results)\n",
        "print(brier_df_36)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "brier_df_36['Brier Score'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Brier score plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define X-axis break points\n",
        "x_ticks = sorted(brier_df_12[\"Time point\"].unique())  # Ensure breaks are correct\n",
        "\n",
        "# Plot each dataframe as a separate line\n",
        "plt.plot(brier_df_12[\"Time point\"], brier_df_12[\"Brier Score\"], marker='o', label=\"Predicting 12 months after\")\n",
        "plt.plot(brier_df_24[\"Time point\"], brier_df_24[\"Brier Score\"], marker='s', label=\"Predicting 24 months after\")\n",
        "plt.plot(brier_df_36[\"Time point\"], brier_df_36[\"Brier Score\"], marker='^', label=\"Predicting 36 months after\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Time Point\")\n",
        "plt.ylabel(\"Brier Score\")\n",
        "plt.title(\"Brier Score at Time Point\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Set x-axis breaks at 12, 24, 36, etc.\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recall score plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define X-axis break points\n",
        "x_ticks = sorted(brier_df_12[\"Time point\"].unique())  # Ensure breaks are correct\n",
        "\n",
        "# Plot each dataframe as a separate line\n",
        "plt.plot(brier_df_12[\"Time point\"], brier_df_12[\"Recall\"], marker='o', label=\"Predicting 12 months after\")\n",
        "plt.plot(brier_df_24[\"Time point\"], brier_df_24[\"Recall\"], marker='s', label=\"Predicting 24 months after\")\n",
        "plt.plot(brier_df_36[\"Time point\"], brier_df_36[\"Recall\"], marker='^', label=\"Predicting 36 months after\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Time Point\")\n",
        "plt.ylabel(\"Recall Score\")\n",
        "plt.title(\"Recall Score at Time Point\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Set x-axis breaks at 12, 24, 36, etc.\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy score plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define X-axis break points\n",
        "x_ticks = sorted(brier_df_12[\"Time point\"].unique())  # Ensure breaks are correct\n",
        "\n",
        "# Plot each dataframe as a separate line\n",
        "plt.plot(brier_df_12[\"Time point\"], brier_df_12[\"Accuracy\"], marker='o', label=\"Predicting 12 months after\")\n",
        "plt.plot(brier_df_24[\"Time point\"], brier_df_24[\"Accuracy\"], marker='s', label=\"Predicting 24 months after\")\n",
        "plt.plot(brier_df_36[\"Time point\"], brier_df_36[\"Accuracy\"], marker='^', label=\"Predicting 36 months after\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Time Point\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.title(\"Accuracy Score at Time Point\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Set x-axis breaks at 12, 24, 36, etc.\n",
        "plt.xticks(x_ticks)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CUSTOMER INSTABILITY INDEX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "active_customers = clean[clean[\"target_label\"] == 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "active_customers[\"last_x1/x1_mean\"] = active_customers[\"last_x1\"] / active_customers[\"x1_mean\"]\n",
        "active_customers[\"last_x2/x2_mean\"] = active_customers[\"last_x2\"] / active_customers[\"x2_mean\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.float_format', '{:.6f}'.format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_ages = active_customers[\"life\"]\n",
        "\n",
        "# Extract corresponding predictor features for the active customers\n",
        "X_active = active_customers[important_features]  # Use the full feature set for all active customers\n",
        "\n",
        "# Define prediction time offset for life + 12\n",
        "time_offset = 12\n",
        "\n",
        "# Compute future time for each customer\n",
        "future_times = customer_ages + time_offset\n",
        "\n",
        "# Predict survival function at these specific times for each customer\n",
        "survival_probs_12 = np.array([\n",
        "    aft_model.predict_survival_function(X_active.iloc[i:i+1], times=[future_times.iloc[i]]).values.flatten()[0]\n",
        "    for i in range(len(X_active))\n",
        "])\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "future_aft_df_12 = pd.DataFrame({\"id\": active_customers[\"id\"], \"life + 12\": survival_probs_12})\n",
        "\n",
        "# Set ID as index\n",
        "future_aft_df_12 = future_aft_df_12.set_index(\"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn_aft_df_12 = 1 - future_aft_df_12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_factors = active_customers[[\"id\", \"last_x1/x1_mean\", \"last_x2/x2_mean\", \"remain_contract_month\", \"last_avg_contract_ratio\"]]\n",
        "\n",
        "# Reset index for future survival probabilities\n",
        "#churn_probs_12 = churn_aft_df_12.reset_index()\n",
        "future_probs_12 = future_aft_df_12.reset_index()\n",
        "\n",
        "# Merge survival probabilities with risk factors\n",
        "risk_df_12 = future_probs_12.merge(risk_factors, on=\"id\", how=\"outer\")\n",
        "\n",
        "\n",
        "# Normalize each feature to be within 0-1\n",
        "risk_df_12[\"last_avg_contract_ratio\"] = risk_df_12[\"last_avg_contract_ratio\"] \n",
        "risk_df_12[\"last_x1/x1_mean\"] = risk_df_12[\"last_x1/x1_mean\"] / risk_df_12[\"last_x1/x1_mean\"].max()\n",
        "risk_df_12[\"last_x2/x2_mean\"] = risk_df_12[\"last_x2/x2_mean\"] / risk_df_12[\"last_x2/x2_mean\"].max()\n",
        "risk_df_12[\"remain_contract_month\"] = risk_df_12[\"remain_contract_month\"] / risk_df_12[\"remain_contract_month\"].max()\n",
        "\n",
        "# Compute risk score with normalized features\n",
        "risk_df_12[\"risk_score\"] = (\n",
        "    risk_df_12[\"life + 12\"] * 0.70 +  # Survival probability is already between 0-1\n",
        "    risk_df_12[\"last_avg_contract_ratio\"] * 0.15 +\n",
        "    risk_df_12[\"last_x1/x1_mean\"] * 0.05 +\n",
        "    risk_df_12[\"last_x2/x2_mean\"] * 0.05 +\n",
        "    risk_df_12[\"remain_contract_month\"] * 0.05\n",
        ") * 100  # Scale to 100\n",
        "\n",
        "# # Clip values to ensure risk score stays within 0-100\n",
        "# risk_df_12[\"risk_score\"] = risk_df_12[\"risk_score\"].clip(0, 100)\n",
        "\n",
        "# Keep only ID and risk score\n",
        "risk_df_12 = risk_df_12[[\"id\", \"risk_score\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "customer_ages = active_customers[\"life\"]\n",
        "\n",
        "# Extract corresponding predictor features for the active customers\n",
        "X_active = active_customers[important_features]  # Use the full feature set for all active customers\n",
        "\n",
        "# Define prediction time offset for life + 24\n",
        "time_offset = 24\n",
        "\n",
        "# Compute future time for each customer\n",
        "future_times = customer_ages + time_offset\n",
        "\n",
        "# Predict survival function at these specific times for each customer\n",
        "survival_probs_24 = np.array([\n",
        "    aft_model.predict_survival_function(X_active.iloc[i:i+1], times=[future_times.iloc[i]]).values.flatten()[0]\n",
        "    for i in range(len(X_active))\n",
        "])\n",
        "\n",
        "# Convert predictions to DataFrame\n",
        "future_aft_df_24 = pd.DataFrame({\"id\": active_customers[\"id\"], \"life + 24\": survival_probs_24})\n",
        "\n",
        "# Set ID as index\n",
        "future_aft_df_24 = future_aft_df_24.set_index(\"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "churn_aft_df_24 = 1 - future_aft_df_24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_factors = active_customers[[\"id\", \"last_x1/x1_mean\", \"last_x2/x2_mean\", \"remain_contract_month\", \"last_avg_contract_ratio\"]]\n",
        "\n",
        "# Reset index for future survival probabilities\n",
        "# churn_probs_24 = churn_aft_df_24.reset_index()\n",
        "future_probs_24 = future_aft_df_24.reset_index()\n",
        "\n",
        "# Merge survival probabilities with risk factors\n",
        "risk_df_24 = future_probs_24.merge(risk_factors, on=\"id\", how=\"outer\")\n",
        "\n",
        "# Normalize each feature to be within 0-1\n",
        "risk_df_24[\"last_avg_contract_ratio\"] = risk_df_24[\"last_avg_contract_ratio\"] \n",
        "risk_df_24[\"last_x1/x1_mean\"] = risk_df_24[\"last_x1/x1_mean\"] / risk_df_24[\"last_x1/x1_mean\"].max()\n",
        "risk_df_24[\"last_x2/x2_mean\"] = risk_df_24[\"last_x2/x2_mean\"] / risk_df_24[\"last_x2/x2_mean\"].max()\n",
        "risk_df_24[\"remain_contract_month\"] = risk_df_24[\"remain_contract_month\"] / risk_df_24[\"remain_contract_month\"].max()\n",
        "\n",
        "# Compute risk score with normalized features\n",
        "risk_df_24[\"risk_score\"] = (\n",
        "    risk_df_24[\"life + 24\"] * 0.70 +  # Survival probability is already between 0-1\n",
        "    risk_df_24[\"last_avg_contract_ratio\"] * 0.15 +\n",
        "    risk_df_24[\"last_x1/x1_mean\"] * 0.05 +\n",
        "    risk_df_24[\"last_x2/x2_mean\"] * 0.05 +\n",
        "    risk_df_24[\"remain_contract_month\"] * 0.05\n",
        ") * 100  # Scale to 100\n",
        "\n",
        "# Keep only ID and risk score\n",
        "risk_df_24 = risk_df_24[[\"id\", \"risk_score\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### combining 12 and 24 month - final approach using the 12 and 24 month weighted average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [],
      "source": [
        "# churn_probs_12 = churn_aft_df_12.reset_index()\n",
        "# churn_probs_24 = churn_aft_df_24.reset_index()\n",
        "\n",
        "\n",
        "# Merge churn probabilities for life + 12 and life + 24 with risk factors\n",
        "risk_df_12_24 = future_probs_12.merge(future_probs_24, on=\"id\", how=\"outer\").merge(risk_factors, on=\"id\", how=\"outer\")\n",
        "\n",
        "# Normalize each feature to be within 0-1\n",
        "risk_df_12_24[\"last_avg_contract_ratio\"] = risk_df_12_24[\"last_avg_contract_ratio\"]\n",
        "risk_df_12_24[\"last_x1/x1_mean\"] = risk_df_12_24[\"last_x1/x1_mean\"] / risk_df_12_24[\"last_x1/x1_mean\"].max()\n",
        "risk_df_12_24[\"last_x2/x2_mean\"] = risk_df_12_24[\"last_x2/x2_mean\"] / risk_df_12_24[\"last_x2/x2_mean\"].max()\n",
        "risk_df_12_24[\"remain_contract_month\"] = risk_df_12_24[\"remain_contract_month\"] / risk_df_12_24[\"remain_contract_month\"].max()\n",
        "\n",
        "# Compute updated risk score with new weightage\n",
        "risk_df_12_24[\"risk_score\"] = (\n",
        "    risk_df_12_24[\"life + 12\"] * 0.40 +  # Weight 40% for life + 12\n",
        "    risk_df_12_24[\"life + 24\"] * 0.30 +  # Weight 30% for life + 24\n",
        "    risk_df_12_24[\"last_avg_contract_ratio\"] * 0.15 +\n",
        "    risk_df_12_24[\"last_x1/x1_mean\"] * 0.05 +\n",
        "    risk_df_12_24[\"last_x2/x2_mean\"] * 0.05 +\n",
        "    risk_df_12_24[\"remain_contract_month\"] * 0.05\n",
        ") * 1  # No additional scaling\n",
        "\n",
        "# Keep only ID and risk score\n",
        "risk_df_12_24 = risk_df_12_24[[\"id\", \"risk_score\"]]\n",
        "\n",
        "# Sort by highest risk score\n",
        "risk_df_12_24_sorted = risk_df_12_24.sort_values(by=\"risk_score\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_df_12_24[\"risk_score\"] = pd.to_numeric(risk_df_12_24[\"risk_score\"], errors=\"coerce\")\n",
        "\n",
        "# Create a new dataframe with 1 - risk_score\n",
        "risk_df_inverse = risk_df_12_24.copy()\n",
        "risk_df_inverse[\"inverse_risk_score\"] = 1 - risk_df_inverse[\"risk_score\"]\n",
        "\n",
        "# Keep only ID and inverse risk score\n",
        "risk_df_inverse = risk_df_inverse[[\"id\", \"inverse_risk_score\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_df_inverse.sort_values(by=\"inverse_risk_score\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CII per category combo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean['Category_Combo'] = clean['cat1'] + '-' + clean['cat2']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_merged = risk_df_inverse.merge(clean[['id', 'Category_Combo']], on='id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_merged.to_csv('risk_merged.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "risk_merged"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
